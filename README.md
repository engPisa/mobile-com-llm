# Mobile com LLM

Este projeto consiste em um aplicativo desenvolvido em Flutter que se comunica com um Modelo de Linguagem Grande (LLM), como o Gemini, utilizando prompts personalizados de acordo com o tema escolhido.

## âš ï¸ Aviso Importante

> âš ï¸ **AtenÃ§Ã£o:** o backend utilizado neste projeto estÃ¡ hospedado em uma instÃ¢ncia gratuita.  
> Sua instÃ¢ncia serÃ¡ desligada automaticamente apÃ³s um perÃ­odo de inatividade, o que pode causar **atrasos de atÃ© 50 segundos ou mais** no tempo de resposta quando for ativada novamente.

## ğŸ“² Baixe o APK

VocÃª pode testar o aplicativo em seu dispositivo Android baixando o APK diretamente pelo link abaixo:

ğŸ‘‰ [Clique aqui para baixar o APK](https://drive.google.com/drive/folders/19uwu4qui367loFbGUGs1UV-WXwIvWHVW?usp=sharing)

## Funcionalidades

- **InteraÃ§Ã£o com LLM**: Permite que os usuÃ¡rios enviem dÃºvidas ou dificuldades e recebam conselhos ou respostas geradas pelo modelo de linguagem.
- **Interface Intuitiva**: Interface amigÃ¡vel que facilita a interaÃ§Ã£o do usuÃ¡rio com o aplicativo.
- **Compatibilidade Multiplataforma**: Projetado para funcionar em diversas plataformas, incluindo Android, iOS, Web, Windows, macOS e Linux.

## Tecnologias Utilizadas

- **Flutter**: Framework principal para o desenvolvimento do aplicativo.
- **Dart**: Linguagem de programaÃ§Ã£o utilizada.
- **flutter_markdown**: Para renderizaÃ§Ã£o de respostas em Markdown.
- **API de LLM**: IntegraÃ§Ã£o com modelos de linguagem como o Gemini para processamento de linguagem natural.

## Estrutura do Projeto

A estrutura do projeto Ã© organizada da seguinte forma:

```bash
mobile-com-llm/ 
            â”œâ”€â”€ lib/ # CÃ³digo fonte principal do aplicativo  
            â”‚    â”œâ”€â”€ main.dart # Ponto de entrada do aplicativo
            â”‚    â””â”€â”€ services/ # ServiÃ§os como a comunicaÃ§Ã£o com a API          
            â”‚        â””â”€â”€ api_service.dart 
            â”œâ”€â”€ backend # DiretÃ³rio raiz do backend
            â”‚    â”œâ”€â”€ app.py # Raiz do backend com a rota
            â”‚    â”œâ”€â”€ Procfile # ConfiguraÃ§Ã£o especifica do render
            â”‚    â””â”€â”€ requirements.txt # DependÃªncias para rodar o ambiente
            â”œâ”€â”€ android/ # CÃ³digo especÃ­fico para a plataforma Android
            â”œâ”€â”€ pubspec.yaml # ConfiguraÃ§Ãµes e dependÃªncias do projeto 
            â””â”€â”€ README.md # DocumentaÃ§Ã£o do projeto
```

## Como Executar o Projeto

1. **PrÃ©-requisitos**:
    - [Flutter](https://docs.flutter.dev/get-started/install) instalado na mÃ¡quina.
    - Dispositivo ou emulador configurado para a plataforma desejada.

2. **Clonar o RepositÃ³rio**:
   ```bash
   git clone https://github.com/engPisa/mobile-com-llm.git
   ```
3. **Instalar as DependÃªncias:**:
    ```bash
      flutter pub get
    ```
4. **Executar o Aplicativo:**:
    ```bash
      flutter run
    ```
#   PersonalizaÃ§Ã£o do Prompt

 > Para personalizar o prompt enviado ao LLM, edite a funÃ§Ã£o getAdvice no arquivo api_service.dart localizado em lib/services/. Por exemplo:

```bash
  final result = await ApiService.getAdvice("Sou um estudante. Minha dÃºvida Ã©: $mensagem");
```
- Altere o texto conforme a necessidade para adaptar o comportamento do modelo Ã s suas especificaÃ§Ãµes.

### ğŸ§‘â€ğŸ’» Autor
Cesar Pisa - Desenvolvedor em evoluÃ§Ã£o ğŸš€
   
